{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:42:02.430237Z",
     "start_time": "2025-07-17T03:42:02.032732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "model_path = \"nanonets/Nanonets-OCR-s\"\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(text=[text], images=[image], padding=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "\n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return output_text[0]\n",
    "\n",
    "image_path = \"/path/to/your/document.jpg\"\n",
    "result = ocr_page_with_nanonets_s(image_path, model, processor, max_new_tokens=15000)\n",
    "print(result)\n"
   ],
   "id": "700c6af5c034d2a6",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n\u001B[1;32m      4\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnanonets/Nanonets-OCR-s\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 6\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForImageTextToText\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     12\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_path)\n",
      "File \u001B[0;32m~/Projects/extraction_by_config/.venv/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:564\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    562\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    563\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[0;32m--> 564\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    570\u001B[0m )\n",
      "File \u001B[0;32m~/Projects/extraction_by_config/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:4142\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   4136\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_autoset_attn_implementation(\n\u001B[1;32m   4137\u001B[0m         config, use_flash_attention_2\u001B[38;5;241m=\u001B[39muse_flash_attention_2, torch_dtype\u001B[38;5;241m=\u001B[39mtorch_dtype, device_map\u001B[38;5;241m=\u001B[39mdevice_map\n\u001B[1;32m   4138\u001B[0m     )\n\u001B[1;32m   4140\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(init_contexts):\n\u001B[1;32m   4141\u001B[0m     \u001B[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001B[39;00m\n\u001B[0;32m-> 4142\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4144\u001B[0m \u001B[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001B[39;00m\n\u001B[1;32m   4145\u001B[0m config \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\n",
      "File \u001B[0;32m~/Projects/extraction_by_config/.venv/lib/python3.9/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1462\u001B[0m, in \u001B[0;36mQwen2_5_VLForConditionalGeneration.__init__\u001B[0;34m(self, config)\u001B[0m\n\u001B[1;32m   1461\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, config):\n\u001B[0;32m-> 1462\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1463\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvisual \u001B[38;5;241m=\u001B[39m Qwen2_5_VisionTransformerPretrainedModel\u001B[38;5;241m.\u001B[39m_from_config(config\u001B[38;5;241m.\u001B[39mvision_config)\n\u001B[1;32m   1464\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m Qwen2_5_VLModel(config)\n",
      "File \u001B[0;32m~/Projects/extraction_by_config/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:1342\u001B[0m, in \u001B[0;36mPreTrainedModel.__init__\u001B[0;34m(self, config, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m   1340\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname_or_path \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mname_or_path\n\u001B[1;32m   1341\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarnings_issued \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m-> 1342\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeneration_config \u001B[38;5;241m=\u001B[39m \u001B[43mGenerationConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_model_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcan_generate() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1343\u001B[0m \u001B[38;5;66;03m# Overwrite the class attribute to make it an instance attribute, so models like\u001B[39;00m\n\u001B[1;32m   1344\u001B[0m \u001B[38;5;66;03m# `InstructBlipForConditionalGeneration` can dynamically update it without modifying the class attribute\u001B[39;00m\n\u001B[1;32m   1345\u001B[0m \u001B[38;5;66;03m# when a different component (e.g. language_model) is used.\u001B[39;00m\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_keep_in_fp32_modules \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mcopy(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m_keep_in_fp32_modules)\n",
      "File \u001B[0;32m~/Projects/extraction_by_config/.venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:1286\u001B[0m, in \u001B[0;36mGenerationConfig.from_model_config\u001B[0;34m(cls, model_config)\u001B[0m\n\u001B[1;32m   1284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m decoder_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_config:\n\u001B[1;32m   1285\u001B[0m     default_generation_config \u001B[38;5;241m=\u001B[39m GenerationConfig()\n\u001B[0;32m-> 1286\u001B[0m     decoder_config_dict \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_dict\u001B[49m()\n\u001B[1;32m   1287\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m generation_config\u001B[38;5;241m.\u001B[39mto_dict()\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m   1288\u001B[0m         is_unset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(generation_config, attr) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(default_generation_config, attr)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'dict' object has no attribute 'to_dict'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-01T04:30:35.710602Z",
     "start_time": "2025-06-01T04:30:35.707741Z"
    }
   },
   "source": [
    "# scratch/test_extraction_item.py\n",
    "\n",
    "from extraction_io.ExtractionItems import ExtractionItem\n",
    "\n",
    "# 1) A valid single-item dict that we want to parse:\n",
    "raw_item = {\n",
    "    \"field_name\": \"BorrowerName\",\n",
    "    \"description\": \"Name of the borrower\",\n",
    "    \"probable_pages\": [1, 2],\n",
    "    \"type\": \"key-value\",          # must match Literal exactly\n",
    "    \"multipage_value\": False,\n",
    "    \"multiline_value\": False,\n",
    "    \"extra_rules\": {\"regex\": \"\\\\w+\"}\n",
    "}\n",
    "\n",
    "# 2) Parse/validate using Pydantic v2's `model_validate`:\n",
    "item = ExtractionItem.model_validate(raw_item)\n",
    "\n",
    "print(\"Parsed ExtractionItem successfully:\")\n",
    "print(f\"  field_name       = {item.field_name!r}\")\n",
    "print(f\"  description      = {item.description!r}\")\n",
    "print(f\"  probable_pages   = {item.probable_pages!r}\")\n",
    "print(f\"  type             = {item.type!r}\")\n",
    "print(f\"  multipage_value  = {item.multipage_value!r}\")\n",
    "print(f\"  multiline_value  = {item.multiline_value!r}\")\n",
    "print(f\"  extra_rules      = {item.extra!r}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ExtractionItem successfully:\n",
      "  field_name       = 'BorrowerName'\n",
      "  description      = 'Name of the borrower'\n",
      "  probable_pages   = [1, 2]\n",
      "  type             = 'key-value'\n",
      "  multipage_value  = False\n",
      "  multiline_value  = False\n",
      "  extra_rules      = {}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T05:55:13.695596Z",
     "start_time": "2025-05-31T05:55:13.690062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# scratch/test_extraction_items.py\n",
    "\n",
    "from extraction_io.ExtractionItems import ExtractionItem, ExtractionItems\n",
    "from pydantic import ValidationError\n",
    "\n",
    "# 1) Example list of two config items:\n",
    "raw_config = [\n",
    "    {\n",
    "        \"field_name\": \"BorrowerName\",\n",
    "        \"description\": \"Name of the borrower\",\n",
    "        \"probable_pages\": [1],\n",
    "        \"type\": \"key-value\",\n",
    "        \"multipage_value\": False,\n",
    "        \"multiline_value\": False,\n",
    "        \"extra_rules\": {\"regex\": \"\\\\w+\"}\n",
    "    },\n",
    "    {\n",
    "        \"field_name\": \"benefits_list\",\n",
    "        \"description\": \"List of benefits\",\n",
    "        # no probable_pages provided ⇒ defaults to []\n",
    "        \"type\": \"bullet-points\",\n",
    "        \"multipage_value\": False,\n",
    "        \"multiline_value\": False,\n",
    "        # omit extra_rules entirely, it will default to {}\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2) Attempt to parse the list as ExtractionItems:\n",
    "try:\n",
    "    config_model = ExtractionItems.model_validate(raw_config)\n",
    "    print(\"Parsed ExtractionItems successfully. Contents:\")\n",
    "    for idx, item in enumerate(config_model):\n",
    "        print(f\"Item {idx}:\")\n",
    "        print(f\"  field_name      = {item.field_name!r}\")\n",
    "        print(f\"  description     = {item.description!r}\")\n",
    "        print(f\"  probable_pages  = {item.probable_pages!r}\")\n",
    "        print(f\"  type            = {item.type!r}\")\n",
    "        print(f\"  multipage_value = {item.multipage_value!r}\")\n",
    "        print(f\"  multiline_value = {item.multiline_value!r}\")\n",
    "        print(f\"  extra_rules     = {item.extra_rules!r}\")\n",
    "        print()\n",
    "except ValidationError as e:\n",
    "    print(\"ValidationError while parsing ExtractionItems:\")\n",
    "    print(e)"
   ],
   "id": "18d75c8d3c66124e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ExtractionItems successfully. Contents:\n",
      "Item 0:\n",
      "  field_name      = 'BorrowerName'\n",
      "  description     = 'Name of the borrower'\n",
      "  probable_pages  = [1]\n",
      "  type            = 'key-value'\n",
      "  multipage_value = False\n",
      "  multiline_value = False\n",
      "  extra_rules     = {'regex': '\\\\w+'}\n",
      "\n",
      "Item 1:\n",
      "  field_name      = 'benefits_list'\n",
      "  description     = 'List of benefits'\n",
      "  probable_pages  = []\n",
      "  type            = 'bullet-points'\n",
      "  multipage_value = False\n",
      "  multiline_value = False\n",
      "  extra_rules     = {}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "702f93614f1576eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
